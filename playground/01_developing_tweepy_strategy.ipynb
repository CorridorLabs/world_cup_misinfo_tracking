{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01_developing_tweepy_strategy\n",
    "In order to stream in relevant tweets for the world cup, we need to figure out how we can: \n",
    "- enable streaming using V2 with tweepy\n",
    "- figure out how we can get the correct fields we need from tweepy\n",
    "- figure out how we can efficiently write this out. one option to investigate could be: mongoDB. but, we will focus on writing this out to json rather than mongodb. \n",
    "\n",
    "NL, 23/11/22  \n",
    "NL, 25/11/22 -- fleshing out, coming up with proper config of our streaming client  \n",
    "NL, 26/11/22 -- moving to py script -> `../data_collection/get_tweets.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import re\n",
    "import datetime\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_path_exists(filepath:str):\n",
    "    '''\n",
    "    checks if a supplied filepath \n",
    "    (dir + filename) exists. if the full path\n",
    "    with file is not a file, checks for \n",
    "    just the dir path and creates file if exists, \n",
    "    raises error if not\n",
    "    \n",
    "    args:\n",
    "        - filepath: str, full file path\n",
    "    '''\n",
    "    if filepath is None:\n",
    "        raise TypeError(f'specified path is None.')\n",
    "\n",
    "    if not isinstance(filepath, str):\n",
    "        raise TypeError(f'filepath object must be\\\n",
    "            str. Please re-specify.')\n",
    "\n",
    "    if os.path.isdir(filepath):\n",
    "        raise ValueError(f'Need to provide a full path to a file,\\\n",
    "            not a dir.')\n",
    "\n",
    "    if not os.path.isfile(filepath):\n",
    "        # split and check if everything before the last \n",
    "        # `/` is a dir\n",
    "        splits = filepath.split('/')\n",
    "        concat = '/'.join(splits[:-1])+'/'\n",
    "        if not os.path.isdir(concat):\n",
    "            raise NotADirectoryError(f'Directory path \\\n",
    "                {concat} does not exist. Please re-specify\\\n",
    "                    `out_path`.')\n",
    "        else:\n",
    "            print(f'{concat}, the dir in for\\\n",
    "                specified filepath is a directory, but\\\n",
    "                    file {splits[-1:]} does not exist.\\\n",
    "                        Thats fine for us.')\n",
    "            return filepath\n",
    "    \n",
    "    else: \n",
    "        return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_count_domains_entities(context_field:list):\n",
    "    '''\n",
    "    entracts the counts of domains and entities in \n",
    "    a given tweet.\n",
    "\n",
    "    returns:\n",
    "        - domains, dict\n",
    "        - entities, dict\n",
    "    '''\n",
    "    domains = {}\n",
    "    entities = {}\n",
    "\n",
    "    for context in context_field:\n",
    "        # domain\n",
    "        if context['domain']['name'] not in domains.keys():\n",
    "            domains[context['domain']['name']] = 1\n",
    "        else:\n",
    "            domains[context['domain']['name']] += 1\n",
    "\n",
    "        # entity\n",
    "        if context['entity']['name'] not in entities.keys():\n",
    "            entities[context['entity']['name']] = 1\n",
    "        else:\n",
    "            entities[context['entity']['name']] += 1\n",
    "\n",
    "    return domains, entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_domain_entity_counts(domains_tweet:dict,\n",
    "                               domains_session:dict,\n",
    "                               entities_tweet:dict,\n",
    "                               entities_session:dict):\n",
    "    ''' \n",
    "    accumulates counts for domains and entities\n",
    "    for the entire streaming session.  \n",
    "    '''\n",
    "    for domain in domains_tweet.keys():\n",
    "        if domain not in domains_session.keys():\n",
    "            domains_session[domain] = 1\n",
    "        else:\n",
    "            domains_session[domain] += 1\n",
    "\n",
    "    for entity in entities_tweet.keys():\n",
    "        if entity not in entities_session.keys():\n",
    "            entities_session[entity] = 1\n",
    "        else:\n",
    "            entities_session[entity] += 1\n",
    "\n",
    "    return domains_session, entities_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_urls(tweet_text:str) -> list:\n",
    "    '''\n",
    "    extracts urls from tweet text\n",
    "    returns all urls in tweet text in list\n",
    "    '''\n",
    "    urls = re.findall(\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", tweet_text)\n",
    "\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PATHS & CONSTANTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_TERMS = '/home/nikloynes/projects/world_cup_misinfo_tracking/data_collection/twitter_search_terms.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consumer_key = os.getenv('TWITTER_API_KEY')\n",
    "# consumer_secret = os.getenv('TWITTER_API_KEY_SECRET')\n",
    "# access_token = os.getenv('TWITTER_ACCESS_TOKEN')\n",
    "# access_token_secret = os.getenv('TWITTER_ACCESS_TOKEN_SECRET')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bearer_token = os.getenv('TWITTER_BEARER_TOKEN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fields to return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "expansions = ['author_id', 'referenced_tweets.id']\n",
    "tweet_fields = ['created_at', 'public_metrics', 'source', 'context_annotations']\n",
    "media_fields = ['media_key', 'type', 'url', 'duration_ms']\n",
    "user_fields = ['id', 'name', 'username', 'created_at', 'description', 'location', 'public_metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetStreamer(tweepy.StreamingClient):\n",
    "\n",
    "    def __init__(self, \n",
    "                 out_path:str,\n",
    "                 out_path_domains:str,\n",
    "                 out_path_entities:str,\n",
    "                 kill_time:int=59,\n",
    "                 time_unit:str='minutes',\n",
    "                 **kwargs):\n",
    "        '''\n",
    "        adding custom params\n",
    "        '''\n",
    "        # out path for our tweet json\n",
    "        out_path = check_path_exists(out_path)\n",
    "        self.outfile = out_path \n",
    "\n",
    "        # out path for our domains/entities jsons\n",
    "        out_path_domains = check_path_exists(out_path_domains)\n",
    "        out_path_entities = check_path_exists(out_path_entities)\n",
    "        self.out_path_domains = out_path_domains\n",
    "        self.out_path_entities = out_path_entities\n",
    "\n",
    "        # timing stuff\n",
    "        self.start_time = datetime.datetime.now()\n",
    "\n",
    "        if time_unit not in ['seconds', 'minutes']:\n",
    "            raise ValueError(f'time_unit must be either `minutes` or `seconds`.')\n",
    "\n",
    "        if time_unit=='minutes':\n",
    "            self.kill_time = datetime.timedelta(seconds=60*kill_time)\n",
    "        else:\n",
    "            self.kill_time = datetime.timedelta(seconds=kill_time)\n",
    "\n",
    "        self.domains = {}\n",
    "        self.entities = {}\n",
    "\n",
    "        # using super here makes sure we get all the attributes\n",
    "        # from our super-class. we do have to pass **kwargs both in\n",
    "        # the init method and here for this to work.\n",
    "        super(TweetStreamer, self).__init__(**kwargs)\n",
    "    \n",
    "    def on_data(self, data):\n",
    "        '''\n",
    "        1. clean the returned tweet object\n",
    "        2. write it out\n",
    "        '''\n",
    "        # pull core fields we want\n",
    "        if (datetime.datetime.now() - self.start_time) <= self.kill_time:\n",
    "\n",
    "            obj = json.loads(data)\n",
    "            tweet = obj['data']\n",
    "            del tweet['edit_history_tweet_ids']\n",
    "\n",
    "            urls = extract_urls(tweet['text'])\n",
    "            if len(urls)>0:\n",
    "                tweet['urls'] = urls\n",
    "\n",
    "            if 'context_annotations' in tweet.keys():\n",
    "                domains, entities = extract_count_domains_entities(tweet['context_annotations'])\n",
    "                self.domains, self.entities = total_domain_entity_counts(domains_tweet=domains,\n",
    "                                                                         domains_session=self.domains,\n",
    "                                                                         entities_tweet=entities,\n",
    "                                                                         entities_session=self.entities)\n",
    "                \n",
    "                # for domain in domains.keys():\n",
    "                #     if domain not in self.domains.keys():\n",
    "                #         self.domains[domain] = 1\n",
    "                #     else:\n",
    "                #         self.domains[domain] += 1\n",
    "\n",
    "                # for entity in entities.keys():\n",
    "                #     if entity not in self.entities.keys():\n",
    "                #         self.entities[entity] = 1\n",
    "                #     else:\n",
    "                #         self.entities[entity] += 1\n",
    "                \n",
    "                del tweet['context_annotations']\n",
    "                tweet['domains'] = domains\n",
    "                tweet['entities'] = entities\n",
    "\n",
    "            tweet['user'] = obj['includes']['users'][0]\n",
    "            \n",
    "            with open(self.outfile, 'a') as o:\n",
    "                o.write(json.dumps(tweet)+'\\n')\n",
    "\n",
    "        # below is the thing that's done\n",
    "        # once we hit the time limit\n",
    "        else:\n",
    "            # write out our domain and entity counts\n",
    "            self.domains = dict(sorted(self.domains.items(), key=lambda x:x[1], reverse=True))\n",
    "            self.entities = dict(sorted(self.entities.items(), key=lambda x:x[1], reverse=True))\n",
    "\n",
    "            with open(self.out_path_domains, 'w') as o:\n",
    "                o.write(json.dumps(self.domains))\n",
    "\n",
    "            with open(self.out_path_entities, 'w') as o:\n",
    "                o.write(json.dumps(self.entities))\n",
    "            \n",
    "            # this kills the streaming process\n",
    "            self.disconnect()\n",
    "            return False\n",
    "\n",
    "\n",
    "    def on_errors(self, errors):\n",
    "        return super().on_errors(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "search term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamer = TweetStreamer(bearer_token=bearer_token, \n",
    "                         out_path='test.json', \n",
    "                         out_path_domains='test_domains.json', \n",
    "                         out_path_entities='test_entities.json',\n",
    "                         kill_time=30,\n",
    "                         time_unit='seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(data=[StreamRule(value='#worldcup', tag=None, id='1596349244906115073'), StreamRule(value='#fifaworldcup', tag=None, id='1596349251424063493'), StreamRule(value='#qatar22', tag=None, id='1596349256411013120'), StreamRule(value='#qatar2022', tag=None, id='1596349262702452743'), StreamRule(value='#qatarworldcup', tag=None, id='1596349269434372096')], includes={}, errors=[], meta={'sent': '2022-11-26T03:52:02.011Z', 'result_count': 5})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamer.get_rules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stream encountered HTTP error: 400\n",
      "HTTP error response text: {\"errors\":[{\"parameters\":{\"backfill_minutes\":[\"1\"]},\"message\":\"Stream is not authorized to use backfill_minutes parameter\"}],\"title\":\"Invalid Request\",\"detail\":\"One or more parameters to your request was invalid.\",\"type\":\"https://api.twitter.com/2/problems/invalid-request\"}\n",
      "Stream encountered HTTP error: 400\n",
      "HTTP error response text: {\"errors\":[{\"parameters\":{\"backfill_minutes\":[\"1\"]},\"message\":\"Stream is not authorized to use backfill_minutes parameter\"}],\"title\":\"Invalid Request\",\"detail\":\"One or more parameters to your request was invalid.\",\"type\":\"https://api.twitter.com/2/problems/invalid-request\"}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m streamer\u001b[39m.\u001b[39;49mfilter(\n\u001b[1;32m      2\u001b[0m     backfill_minutes\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m      3\u001b[0m     expansions\u001b[39m=\u001b[39;49mexpansions, \n\u001b[1;32m      4\u001b[0m     tweet_fields\u001b[39m=\u001b[39;49mtweet_fields,\n\u001b[1;32m      5\u001b[0m     media_fields\u001b[39m=\u001b[39;49mmedia_fields,\n\u001b[1;32m      6\u001b[0m     user_fields\u001b[39m=\u001b[39;49muser_fields\n\u001b[1;32m      7\u001b[0m     )\n",
      "File \u001b[0;32m~/projects/world_cup_misinfo_tracking/.venv/lib/python3.10/site-packages/tweepy/streaming.py:806\u001b[0m, in \u001b[0;36mStreamingClient.filter\u001b[0;34m(self, threaded, **params)\u001b[0m\n\u001b[1;32m    804\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threaded_connect(method, endpoint, params\u001b[39m=\u001b[39mparams)\n\u001b[1;32m    805\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 806\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_connect(method, endpoint, params\u001b[39m=\u001b[39;49mparams)\n",
      "File \u001b[0;32m~/projects/world_cup_misinfo_tracking/.venv/lib/python3.10/site-packages/tweepy/streaming.py:626\u001b[0m, in \u001b[0;36mStreamingClient._connect\u001b[0;34m(self, method, endpoint, **kwargs)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession\u001b[39m.\u001b[39mheaders[\u001b[39m\"\u001b[39m\u001b[39mAuthorization\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBearer \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbearer_token\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    625\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://api.twitter.com/2/tweets/\u001b[39m\u001b[39m{\u001b[39;00mendpoint\u001b[39m}\u001b[39;00m\u001b[39m/stream\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 626\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_connect(method, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/projects/world_cup_misinfo_tracking/.venv/lib/python3.10/site-packages/tweepy/streaming.py:120\u001b[0m, in \u001b[0;36mBaseStream._connect\u001b[0;34m(self, method, url, auth, params, headers, body, timeout)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[39mif\u001b[39;00m http_error_wait \u001b[39m<\u001b[39m http_429_error_wait_start:\n\u001b[1;32m    118\u001b[0m         http_error_wait \u001b[39m=\u001b[39m http_429_error_wait_start\n\u001b[0;32m--> 120\u001b[0m sleep(http_error_wait)\n\u001b[1;32m    122\u001b[0m http_error_wait \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m    123\u001b[0m \u001b[39mif\u001b[39;00m http_error_wait \u001b[39m>\u001b[39m http_error_wait_max:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "streamer.filter(\n",
    "    # backfill_minutes=1,\n",
    "    expansions=expansions, \n",
    "    tweet_fields=tweet_fields,\n",
    "    media_fields=media_fields,\n",
    "    user_fields=user_fields\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = streamer.get_rules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1596186239585091585\n",
      "<class 'str'>\n",
      "1596342722381725697\n",
      "<class 'str'>\n",
      "1596342810608803846\n",
      "<class 'str'>\n",
      "1596342810608803847\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for rule in test.data:\n",
    "    print(rule.id)\n",
    "    print(type(rule.id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(data=[StreamRule(value='wagner', tag=None, id='1596342810608803847'), StreamRule(value='bernhard', tag=None, id='1596342810608803846')], includes={}, errors=[], meta={'sent': '2022-11-26T03:19:20.506Z', 'summary': {'created': 2, 'not_created': 0, 'valid': 2, 'invalid': 0}})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamer.add_rules([tweepy.StreamRule('bernhard'), tweepy.StreamRule('wagner')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "StreamingClient.delete_rules() missing 1 required positional argument: 'ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m streamer\u001b[39m.\u001b[39;49mdelete_rules()\n",
      "\u001b[0;31mTypeError\u001b[0m: StreamingClient.delete_rules() missing 1 required positional argument: 'ids'"
     ]
    }
   ],
   "source": [
    "streamer.delete_rules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(data=None, includes={}, errors=[{'value': 'gakpo', 'id': '1596186239585091585', 'title': 'DuplicateRule', 'type': 'https://api.twitter.com/2/problems/duplicate-rules'}], meta={'sent': '2022-11-26T01:39:57.762Z', 'summary': {'created': 0, 'not_created': 1, 'valid': 0, 'invalid': 1}})"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamer.add_rules(tweepy.StreamRule('gakpo'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trying to read in tweets just collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "\n",
    "with open('test.json', 'r') as infile:\n",
    "    for line in infile:\n",
    "        tweets.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['https://t.co/ZPAvtQGg4c']\n",
      "[]\n",
      "[]\n",
      "['https://t.co/rliImuBHdH']\n",
      "[]\n",
      "['https://t.co/RJuzctV88l']\n",
      "['https://t.co/mVxWYkx58k']\n",
      "['https://t.co/o7wYgjz4vF']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['https://t.co/GgxC8XMKCF']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['https://t.co/onYErP7wvR']\n",
      "['https://t.co/s9L0ArwoYk']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['https://t.co/EWIfj3hIW5']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for tweet in tweets:\n",
    "    urls = re.findall(\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", tweet['text'])\n",
    "    print(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_TODAY = datetime.datetime.now()\n",
    "TODAY = DT_TODAY.strftime('%Y_%m_%d-%H_%M_%S')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022_11_26-02_56_32'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TODAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 'this is a piece of text with 2 urls: https://t.co/GgxC8XMKCF and https://t.co/EWIfj3hIW5' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://t.co/GgxC8XMKCF', 'https://t.co/EWIfj3hIW5']"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author_id': '602101529',\n",
       " 'created_at': '2022-11-25T17:19:25.000Z',\n",
       " 'edit_history_tweet_ids': ['1596191840675717122'],\n",
       " 'id': '1596191840675717122',\n",
       " 'public_metrics': {'retweet_count': 1,\n",
       "  'reply_count': 0,\n",
       "  'like_count': 0,\n",
       "  'quote_count': 0},\n",
       " 'referenced_tweets': [{'type': 'retweeted', 'id': '1596191759746224129'}],\n",
       " 'source': 'Twitter for Android',\n",
       " 'text': 'RT @pbtips_: Gakpo dey defence and Attack'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[0]['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author_id': '602101529',\n",
       " 'created_at': '2022-11-25T17:19:25.000Z',\n",
       " 'edit_history_tweet_ids': ['1596191840675717122'],\n",
       " 'id': '1596191840675717122',\n",
       " 'public_metrics': {'retweet_count': 1,\n",
       "  'reply_count': 0,\n",
       "  'like_count': 0,\n",
       "  'quote_count': 0},\n",
       " 'referenced_tweets': [{'type': 'retweeted', 'id': '1596191759746224129'}],\n",
       " 'source': 'Twitter for Android',\n",
       " 'text': 'RT @pbtips_: Gakpo dey defence and Attack'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[0]['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'users': [{'created_at': '2012-06-07T18:42:55.000Z',\n",
       "   'description': '★Free Sports Betting Tips  ★ Blogs on @eldanaija ★ Redesign your blog ★ DM for ADs & Promotion ★ Aspiring Video animator ★\\n📩 touchedbyelda@gmail.com',\n",
       "   'id': '602101529',\n",
       "   'location': 'Nigeria',\n",
       "   'name': 'Obinna | #ObiDatti2023💙',\n",
       "   'public_metrics': {'followers_count': 10431,\n",
       "    'following_count': 9141,\n",
       "    'tweet_count': 391228,\n",
       "    'listed_count': 12},\n",
       "   'username': 'touchedByElda'},\n",
       "  {'created_at': '2018-09-01T21:19:48.000Z',\n",
       "   'description': 'FOOTBALL/BASKETBALL TIPSTER 📩Professionalbetstip@gmail.com Please gamble responsibly! 18+ https://t.co/Kdf976xDDj',\n",
       "   'id': '1036000695533690880',\n",
       "   'location': 'Africa',\n",
       "   'name': 'PROFESSIONAL BETS',\n",
       "   'public_metrics': {'followers_count': 164432,\n",
       "    'following_count': 1324,\n",
       "    'tweet_count': 78425,\n",
       "    'listed_count': 380},\n",
       "   'username': 'pbtips_'}],\n",
       " 'tweets': [{'author_id': '602101529',\n",
       "   'created_at': '2022-11-25T17:19:25.000Z',\n",
       "   'edit_history_tweet_ids': ['1596191840675717122'],\n",
       "   'id': '1596191840675717122',\n",
       "   'public_metrics': {'retweet_count': 1,\n",
       "    'reply_count': 0,\n",
       "    'like_count': 0,\n",
       "    'quote_count': 0},\n",
       "   'referenced_tweets': [{'type': 'retweeted', 'id': '1596191759746224129'}],\n",
       "   'source': 'Twitter for Android',\n",
       "   'text': 'RT @pbtips_: Gakpo dey defence and Attack'},\n",
       "  {'author_id': '1036000695533690880',\n",
       "   'created_at': '2022-11-25T17:19:05.000Z',\n",
       "   'edit_history_tweet_ids': ['1596191759746224129'],\n",
       "   'id': '1596191759746224129',\n",
       "   'public_metrics': {'retweet_count': 1,\n",
       "    'reply_count': 1,\n",
       "    'like_count': 2,\n",
       "    'quote_count': 0},\n",
       "   'source': 'Twitter for iPhone',\n",
       "   'text': 'Gakpo dey defence and Attack'}]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[0]['includes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"data\":{\"author_id\":\"848043269103558660\",\"created_at\":\"2022-11-25T22:45:10.000Z\",\"edit_history_tweet_ids\":[\"1596273819580518400\"],\"id\":\"1596273819580518400\",\"public_metrics\":{\"retweet_count\":292,\"reply_count\":0,\"like_count\":0,\"quote_count\":0},\"referenced_tweets\":[{\"type\":\"retweeted\",\"id\":\"1596184708177694720\"}],\"source\":\"Twitter for iPhone\",\"text\":\"RT @FIFAWorldCup: Gakpo\\'s strike gives #NED the advantage at the break. \\\\n\\\\n#FIFAWorldCup | #Qatar2022\"},\"includes\":{\"users\":[{\"created_at\":\"2017-04-01T05:24:06.000Z\",\"description\":\"We Are X\\xef\\xbc\\x81I love X forever\\xef\\xbc\\x81\\xef\\xbc\\x81 X=\\xe7\\x84\\xa1\\xe9\\x99\\x90\\xe3\\x81\\xae\\xe5\\x8f\\xaf\\xe8\\x83\\xbd\\xe6\\x80\\xa7\\xe3\\x82\\x92\\xe6\\x84\\x8f\\xe8\\xad\\x98\\xe3\\x81\\x97\\xe3\\x81\\xa6\\xe8\\xb5\\xb0\\xe3\\x82\\x8b\\xe7\\xa4\\xbe\\xe4\\xbc\\x9a\\xe4\\xba\\xba\\xe3\\x80\\x82\\xe5\\x85\\x83\\xe7\\xa7\\x8b\\xe8\\x91\\x89\\xe4\\xba\\xba\\xe3\\x80\\x82\",\"id\":\"848043269103558660\",\"location\":\"X\",\"name\":\"YOSHIKI2\\xe4\\xb8\\x96\",\"public_metrics\":{\"followers_count\":169,\"following_count\":451,\"tweet_count\":17264,\"listed_count\":0},\"username\":\"OCEAN6666\"},{\"created_at\":\"2010-04-29T10:58:07.000Z\",\"description\":\"The official Twitter account of the FIFA World Cup! All highlights and where to watch live matches on FIFA+ \\xe2\\xac\\x87\\xef\\xb8\\x8f\",\"id\":\"138372303\",\"name\":\"FIFA World Cup\",\"public_metrics\":{\"followers_count\":11162713,\"following_count\":608,\"tweet_count\":30638,\"listed_count\":16124},\"username\":\"FIFAWorldCup\"}],\"tweets\":[{\"author_id\":\"848043269103558660\",\"created_at\":\"2022-11-25T22:45:10.000Z\",\"edit_history_tweet_ids\":[\"1596273819580518400\"],\"id\":\"1596273819580518400\",\"public_metrics\":{\"retweet_count\":292,\"reply_count\":0,\"like_count\":0,\"quote_count\":0},\"referenced_tweets\":[{\"type\":\"retweeted\",\"id\":\"1596184708177694720\"}],\"source\":\"Twitter for iPhone\",\"text\":\"RT @FIFAWorldCup: Gakpo\\'s strike gives #NED the advantage at the break. \\\\n\\\\n#FIFAWorldCup | #Qatar2022\"},{\"author_id\":\"138372303\",\"created_at\":\"2022-11-25T16:51:04.000Z\",\"edit_history_tweet_ids\":[\"1596184708177694720\"],\"id\":\"1596184708177694720\",\"public_metrics\":{\"retweet_count\":292,\"reply_count\":550,\"like_count\":2479,\"quote_count\":44},\"source\":\"Twitter for Advertisers\",\"text\":\"Gakpo\\'s strike gives #NED the advantage at the break. \\\\n\\\\n#FIFAWorldCup | #Qatar2022\"}]},\"matching_rules\":[{\"id\":\"1596186239585091585\",\"tag\":\"\"}]}'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamer.tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "below is some code which streams tweets and automatically writes them to a mongodb. this is something we might want to pursue. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# twitter-to-mongo.py v1.0 Created by Nacho Gaona\n",
    "# ===============================================\n",
    "import pymongo\n",
    "import json\n",
    "from tweepy.streaming import Stream\n",
    "from tweepy import OAuthHandler\n",
    "import datetime\n",
    "import tweepy\n",
    "\n",
    "\n",
    "# The MongoDB connection info. This assumes your database name is TwitterStream, and your collection name is tweets.\n",
    "connection =  pymongo.MongoClient('localhost', 27017)\n",
    "db = connection.TwitterStream  #youshould have a DB created with name TwitterStream\n",
    "\n",
    "\n",
    "collection = db.tweets      #youshould have a collection created with name tweets\n",
    "\n",
    "\n",
    "# Optional - Only grab tweets of specific language\n",
    "language = ['en']\n",
    "\n",
    "# You need to replace these with your own values that you get after creating an app on Twitter's developer portal.\n",
    "consumer_key = \"XX\"\n",
    "consumer_secret = \"XX\"\n",
    "access_token = \"XX-XX\"\n",
    "access_token_secret = \"XX\"\n",
    "\n",
    "\n",
    "\n",
    "# The below code will get Tweets from the stream and store only the important fields to your database\n",
    "class MyStreamListener(Stream):\n",
    "\n",
    "    def on_data(self, data):\n",
    "\n",
    "        # Load the Tweet into the variable \"t\"\n",
    "        t = json.loads(data)\n",
    "\n",
    "        # Pull important data from the tweet to store in the database.\n",
    "        tweet_id = t['id_str']  # The Tweet ID from Twitter in string format\n",
    "        username = t['user']['screen_name']  # The username of the Tweet author\n",
    "        followers = t['user']['followers_count']  # The number of followers the Tweet author has\n",
    "        text = t['text']  # The entire body of the Tweet\n",
    "        hashtags = t['entities']['hashtags']  # Any hashtags used in the Tweet\n",
    "        dt = t['created_at']  # The timestamp of when the Tweet was created\n",
    "        language = t['lang']  # The language of the Tweet\n",
    "\n",
    "        # Convert the timestamp string given by Twitter to a date object called \"created\". This is more easily manipulated in MongoDB.\n",
    "        created = datetime.datetime.strptime(dt, '%a %b %d %H:%M:%S +0000 %Y')\n",
    "\n",
    "        # Load all of the extracted Tweet data into the variable \"tweet\" that will be stored into the database\n",
    "        tweet = {'id':tweet_id, 'username':username, 'followers':followers, 'text':text, 'hashtags':hashtags, 'language':language, 'created':created}\n",
    "\n",
    "        # Save the refined Tweet data to MongoDB\n",
    "        collection.insert_one(tweet)\n",
    "\n",
    "        # Optional - Print the username and text of each Tweet to your console in realtime as they are pulled from the stream\n",
    "        print(username + ':' + ' ' + text)\n",
    "        return True\n",
    "\n",
    "    # Prints the reason for an error to your console\n",
    "    def on_error(self, status):\n",
    "        print (status)\n",
    "\n",
    "# Some Tweepy code that can be left alone. It pulls from variables at the top of the script\n",
    "if __name__ == '__main__':\n",
    "\n",
    "\n",
    "  \n",
    "    myStreamListener_new = MyStreamListener(consumer_key,consumer_secret,access_token,access_token_secret)\n",
    "    myStreamListener_new.filter(track=['Pique'])\n",
    "\n",
    "\n",
    "\n",
    "    ###########################\n",
    "    #in case you want check updates from twitter timeline\n",
    "    #auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    #auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "    #api = tweepy.API(auth)\n",
    "    #public_tweets = api.home_timeline()\n",
    "    #for tweete in public_tweets:  #this is another example to check the timeline from twits\n",
    "    #    print (tweete.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c9d1feaa8e9cddc59f1ae355950f3806cb42c4260f42587cbc52f3c11be4e1e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
