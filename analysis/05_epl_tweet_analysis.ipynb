{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05_epl_tweet_analysis\n",
    "In addition to the analysis we conducted for the world cup,  we are repeating a similar tweet-level analysis with a focus on URLs for the recent round of premier league fixtures. Specifically, we collected tweets for:\n",
    "- Liverpool vs Chelsea (21/01/23, 12:30 GMT)\n",
    "- Arsenal vs Man United (22/01/23, 16:30 GMT)\n",
    "\n",
    "For both of these games, we got tweets for one our before and after kickoff as well as during the game. \n",
    "\n",
    "This analysis will be structured as follows:\n",
    "- summary-stats - number of tweets, volume by time, comparing the two datasets, etc.\n",
    "- extracting URLs and expanding them\n",
    "\n",
    "NL, 23/01/23"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PATHS & CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TWEETS_PATH = '/home/nikloynes/projects/world_cup_misinfo_tracking/data/epl_tweets/'\n",
    "DAY_1_PATH = TWEETS_PATH+'210123/'\n",
    "DAY_2_PATH = TWEETS_PATH+'220123/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORT_PATH = '/home/nikloynes/projects/world_cup_misinfo_tracking/data/exports/epl_tweets/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THE THING!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting out and reading in tweet & URL data... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_files = os.listdir(DAY_1_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_files.remove('epl_tweets_2023_01_18-15_43_42.json') # data from testing\n",
    "tweet_files.remove('meta') # meta dir\n",
    "tweet_files.remove('epl_tweets_2023_01_18-15_50_01.json') # data from testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_files = [DAY_1_PATH+x for x in tweet_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = os.listdir(DAY_2_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.remove('meta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_files += [DAY_2_PATH+x for x in tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/nikloynes/projects/world_cup_misinfo_tracking/data/epl_tweets/210123/epl_tweets_2023_01_21-11_30_01.json',\n",
       " '/home/nikloynes/projects/world_cup_misinfo_tracking/data/epl_tweets/210123/epl_tweets_2023_01_21-12_30_01.json',\n",
       " '/home/nikloynes/projects/world_cup_misinfo_tracking/data/epl_tweets/210123/epl_tweets_2023_01_21-13_30_01.json',\n",
       " '/home/nikloynes/projects/world_cup_misinfo_tracking/data/epl_tweets/210123/epl_tweets_2023_01_21-14_30_01.json',\n",
       " '/home/nikloynes/projects/world_cup_misinfo_tracking/data/epl_tweets/220123/epl_tweets_2023_01_22-15_30_01.json',\n",
       " '/home/nikloynes/projects/world_cup_misinfo_tracking/data/epl_tweets/220123/epl_tweets_2023_01_22-16_30_01.json',\n",
       " '/home/nikloynes/projects/world_cup_misinfo_tracking/data/epl_tweets/220123/epl_tweets_2023_01_22-17_30_01.json',\n",
       " '/home/nikloynes/projects/world_cup_misinfo_tracking/data/epl_tweets/220123/epl_tweets_2023_01_22-18_30_02.json']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulling all tweets and all URL-sharing instances into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:26<00:00,  3.32s/it]\n"
     ]
    }
   ],
   "source": [
    "all_tweets = []\n",
    "all_urls_timestamps = []\n",
    "\n",
    "for file in tqdm(tweet_files):\n",
    "    with open(file, 'r') as infile:\n",
    "        for line in infile:\n",
    "            \n",
    "            # tweets\n",
    "            tmp = json.loads(line)\n",
    "            if 'domains' in tmp.keys():\n",
    "                del tmp['domains']\n",
    "            if 'entities' in tmp.keys():\n",
    "                del tmp['entities']\n",
    "            all_tweets.append(tmp)\n",
    "\n",
    "            # urls\n",
    "            if 'urls' in tmp.keys():\n",
    "                for item in tmp['urls']:\n",
    "                    all_urls_timestamps.append({'url' : item, 'timestamp' : tmp['created_at']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1141414"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets_df = pd.DataFrame(all_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets_df = all_tweets_df.rename(columns={'id' : 'tweet_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets_df = pd.concat([all_tweets_df.drop(['public_metrics'], axis=1), all_tweets_df['public_metrics'].apply(pd.Series)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets_df = pd.concat([all_tweets_df.drop(['user'], axis=1), all_tweets_df['user'].apply(pd.Series)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets_df = all_tweets_df.rename(columns={'id' : 'user_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets_df = pd.concat([all_tweets_df.drop(['public_metrics'], axis=1), all_tweets_df['public_metrics'].apply(pd.Series)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets_df = all_tweets_df.rename(columns = {all_tweets_df.columns[1] : 'tweet_created_at', all_tweets_df.columns[11] : 'user_created_at'})    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A total of `1,141,414` tweets were collected over both data collection periods."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting URLs and sending to a separate process for expansion... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "542944"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_urls_timestamps_df = pd.DataFrame(all_urls_timestamps)\n",
    "len(all_urls_timestamps_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.56766607033031"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_urls_timestamps)/len(all_tweets)*100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A total of `542,944` link-sharing incidences in our entire sample, out of a total of `1,141,414` tweets. So, `~47.6%` of tweets contained a URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_urls_freqs_df = all_urls_timestamps_df.groupby('url').count().reset_index().rename(columns={'timestamp' : 'freq'}).sort_values('freq', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186024"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_urls_freqs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://t.co/Dw9ltLW7T7</td>\n",
       "      <td>10226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://t.co/1Tbu8SP8p9</td>\n",
       "      <td>5924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://t</td>\n",
       "      <td>5681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://t.co/hnt6oNc0Nw</td>\n",
       "      <td>3202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://t.co/eZnJLPp6B5</td>\n",
       "      <td>2810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       url   freq\n",
       "0  https://t.co/Dw9ltLW7T7  10226\n",
       "1  https://t.co/1Tbu8SP8p9   5924\n",
       "2                https://t   5681\n",
       "3  https://t.co/hnt6oNc0Nw   3202\n",
       "4  https://t.co/eZnJLPp6B5   2810"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_urls_freqs_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a total of `186024` unique (shortened) URLs. Let us now export these for expansion... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_urls_freqs_df.to_csv(EXPORT_PATH+'unique_urls_freqs.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Users"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what our tweet dataset looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>public_metrics</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>urls</th>\n",
       "      <th>withheld</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1306264256384503810</td>\n",
       "      <td>2023-01-21T11:30:14.000Z</td>\n",
       "      <td>1616760076613685248</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>[{'type': 'replied_to', 'id': '161640912456818...</td>\n",
       "      <td>@1cEphraimCFC Lol trash ke?</td>\n",
       "      <td>{'created_at': '2020-09-16T16:10:56.000Z', 'de...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1313192105439711234</td>\n",
       "      <td>2023-01-21T11:30:14.000Z</td>\n",
       "      <td>1616760076043423745</td>\n",
       "      <td>{'retweet_count': 191, 'reply_count': 0, 'like...</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1616758845757607...</td>\n",
       "      <td>RT @TrollFootball: Liverpool vs Chelsea be lik...</td>\n",
       "      <td>{'created_at': '2020-10-05T18:59:41.000Z', 'de...</td>\n",
       "      <td>[https://t.co/2NrxYozag2]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1473100428015513604</td>\n",
       "      <td>2023-01-21T11:30:15.000Z</td>\n",
       "      <td>1616760078434201600</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>[{'type': 'quoted', 'id': '1616759107096088576'}]</td>\n",
       "      <td>Klopp Salope t‚Äôas chaud ou quoi üòÇüòÇüòÇü´µüèæ https://...</td>\n",
       "      <td>{'created_at': '2021-12-21T01:18:22.000Z', 'de...</td>\n",
       "      <td>[https://t.co/aEltVjkUt2]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1469337076579643392</td>\n",
       "      <td>2023-01-21T11:30:15.000Z</td>\n",
       "      <td>1616760078782332931</td>\n",
       "      <td>{'retweet_count': 10, 'reply_count': 0, 'like_...</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1616759242450472...</td>\n",
       "      <td>RT @the_smallie: This Chelsea Vs Liverpool mat...</td>\n",
       "      <td>{'created_at': '2021-12-10T16:04:26.000Z', 'de...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1546112807321600001</td>\n",
       "      <td>2023-01-21T11:30:15.000Z</td>\n",
       "      <td>1616760077574176772</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>[{'type': 'replied_to', 'id': '161669937602545...</td>\n",
       "      <td>@FrankKhalidUK All of them</td>\n",
       "      <td>{'created_at': '2022-07-10T12:43:32.000Z', 'de...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author_id                created_at                   id  \\\n",
       "0  1306264256384503810  2023-01-21T11:30:14.000Z  1616760076613685248   \n",
       "1  1313192105439711234  2023-01-21T11:30:14.000Z  1616760076043423745   \n",
       "2  1473100428015513604  2023-01-21T11:30:15.000Z  1616760078434201600   \n",
       "3  1469337076579643392  2023-01-21T11:30:15.000Z  1616760078782332931   \n",
       "4  1546112807321600001  2023-01-21T11:30:15.000Z  1616760077574176772   \n",
       "\n",
       "                                      public_metrics  \\\n",
       "0  {'retweet_count': 0, 'reply_count': 0, 'like_c...   \n",
       "1  {'retweet_count': 191, 'reply_count': 0, 'like...   \n",
       "2  {'retweet_count': 0, 'reply_count': 0, 'like_c...   \n",
       "3  {'retweet_count': 10, 'reply_count': 0, 'like_...   \n",
       "4  {'retweet_count': 0, 'reply_count': 0, 'like_c...   \n",
       "\n",
       "                                   referenced_tweets  \\\n",
       "0  [{'type': 'replied_to', 'id': '161640912456818...   \n",
       "1  [{'type': 'retweeted', 'id': '1616758845757607...   \n",
       "2  [{'type': 'quoted', 'id': '1616759107096088576'}]   \n",
       "3  [{'type': 'retweeted', 'id': '1616759242450472...   \n",
       "4  [{'type': 'replied_to', 'id': '161669937602545...   \n",
       "\n",
       "                                                text  \\\n",
       "0                        @1cEphraimCFC Lol trash ke?   \n",
       "1  RT @TrollFootball: Liverpool vs Chelsea be lik...   \n",
       "2  Klopp Salope t‚Äôas chaud ou quoi üòÇüòÇüòÇü´µüèæ https://...   \n",
       "3  RT @the_smallie: This Chelsea Vs Liverpool mat...   \n",
       "4                         @FrankKhalidUK All of them   \n",
       "\n",
       "                                                user  \\\n",
       "0  {'created_at': '2020-09-16T16:10:56.000Z', 'de...   \n",
       "1  {'created_at': '2020-10-05T18:59:41.000Z', 'de...   \n",
       "2  {'created_at': '2021-12-21T01:18:22.000Z', 'de...   \n",
       "3  {'created_at': '2021-12-10T16:04:26.000Z', 'de...   \n",
       "4  {'created_at': '2022-07-10T12:43:32.000Z', 'de...   \n",
       "\n",
       "                        urls withheld  \n",
       "0                        NaN      NaN  \n",
       "1  [https://t.co/2NrxYozag2]      NaN  \n",
       "2  [https://t.co/aEltVjkUt2]      NaN  \n",
       "3                        NaN      NaN  \n",
       "4                        NaN      NaN  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_users_df = all_tweets_df.groupby('author_id').count()[['text']].reset_index().merge(all_tweets_df.groupby('author_id').sum()[['retweet_count', 'reply_count', 'like_count', 'quote_count']].reset_index(), on='author_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c9d1feaa8e9cddc59f1ae355950f3806cb42c4260f42587cbc52f3c11be4e1e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
